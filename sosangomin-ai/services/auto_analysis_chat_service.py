# services/auto_chat_service.py

import os
import logging
import json
from typing import Dict, Any
from anthropic import Anthropic
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

class AutoAnalysisChatService:
    def __init__(self):
        load_dotenv("./config/.env")
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            logger.error("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            api_key = "NOT_SET"  
        
        self.client = Anthropic(api_key=api_key)
        
        self.system_prompt = """
        ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ë°ì´í„° ë¶„ì„ í”Œë«í¼ì—ì„œ ì¼í•˜ëŠ” ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ì—­í• ì€ ë°ì´í„°ë¥¼ ì˜ ëª¨ë¥´ëŠ” ì‚¬ìš©ìì—ê²Œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‰½ê³ , ì‹¤ìš©ì ì´ë©°, ì¹œì ˆí•˜ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        [ë§¤ì¶œ ì˜ˆì¸¡ ê²°ê³¼ ì„¤ëª…]
        - í–¥í›„ 30ì¼ ì˜ˆì¸¡ëœ ë§¤ì¶œ íë¦„ì„ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
        - ë§¤ì¶œì´ ë†’ê±°ë‚˜ ë‚®ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹œê¸°ì™€ ê·¸ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
        - ì´ ì˜ˆìƒ ë§¤ì¶œ, ì¼í‰ê·  ë§¤ì¶œ ë“±ì„ í¬í•¨í•´ ì‹¤ì œ ì–¼ë§ˆë‚˜ ë²Œ ê²ƒ ê°™ì€ì§€ ê°ì´ ì˜¤ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
        - ì§€ë‚œë‹¬ ëŒ€ë¹„ ì¦ê°ë„ í¬í•¨í•´ ì£¼ì„¸ìš”.
        - ìš´ì˜ì— ë„ì›€ì´ ë  ë§Œí•œ ì‹¤ì§ˆì ì¸ ì¡°ì–¸(ì¬ê³ , ì¸ë ¥, ì´ë²¤íŠ¸ ì „ëµ ë“±)ì„ í•¨ê»˜ ì œì•ˆí•˜ì„¸ìš”.
        - ìˆ«ìì— ëŒ€í•œ ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ í‰ê°€ ì§€í‘œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

        [í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì„¤ëª…]
        - ë¹„ìŠ·í•œ ìƒí’ˆë“¤ì„ ì–´ë–»ê²Œ ë‚˜ëˆ„ì—ˆëŠ”ì§€ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
        - ê° ê·¸ë£¹(í´ëŸ¬ìŠ¤í„°)ì˜ íŠ¹ì§•ì„ ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ì†Œê°œí•˜ê³ , ì–´ë–»ê²Œ í™œìš©í•˜ë©´ ì¢‹ì„ì§€ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        - ì–´ë ¤ìš´ í†µê³„ ìš©ì–´ëŠ” ì“°ì§€ ë§ê³ , ì‹¤ì œ ì¥ì‚¬ì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
    
    async def generate_sales_predict_summary(self, prediction_result: Dict[str, Any]) -> str:
        """ì†Œìƒê³µì¸ì„ ìœ„í•œ í–¥í›„ 30ì¼ ë§¤ì¶œ ì˜ˆì¸¡ ì„¤ëª… ìƒì„±"""
        try:
            previous_data = prediction_result.get("previous_30_days", [])
            previous_data_str = json.dumps(previous_data, ensure_ascii=False, indent=2)
            predict_data = prediction_result.get("predictions", [])
            predict_data_str = json.dumps(predict_data, ensure_ascii=False, indent=2)
            summary = prediction_result.get("summary", {})
            performance = prediction_result.get("performance", {})
            seasonal_trend = prediction_result.get("seasonal_trend", [])

            total_sales = summary.get("total_sales", 0)
            avg_sales = summary.get("average_daily_sales", 0)
            max_sales = summary.get("max_sales", {})
            min_sales = summary.get("min_sales", {})

            mape = performance.get("mape", None)
            rmse = performance.get("rmse", None)
            
            # ë‚ ì§œ ë° ë§¤ì¶œ ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸ ê°„ëµ ìš”ì•½
            # preview = predict_data[:5]
            # preview_text = f"{preview} ... (ì™¸ {len(predict_data)-5}ì¼)"

            prompt = f"""
            ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ë°ì´í„° ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë‹¤ìŒì€ í–¥í›„ 30ì¼ê°„ì˜ ë§¤ì¶œ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.

            ğŸ“Š ìš”ì•½ ì •ë³´
            - ì´ ì˜ˆìƒ ë§¤ì¶œ: ì•½ {round(total_sales):,}ì›
            - í•˜ë£¨ í‰ê·  ë§¤ì¶œ: ì•½ {round(avg_sales):,}ì›
            - ê°€ì¥ ë†’ì€ ë§¤ì¶œ ì˜ˆìƒì¼: {max_sales.get("date")}ì¼ ({round(max_sales.get("value", 0)):,}ì›)
            - ê°€ì¥ ë‚®ì€ ë§¤ì¶œ ì˜ˆìƒì¼: {min_sales.get("date")}ì¼ ({round(min_sales.get("value", 0)):,}ì›)
            
            ğŸ“… ì´ì „ 30ì¼ ì‹¤ì œ ë§¤ì¶œ ë°ì´í„°:
            {previous_data} 

            ğŸ“… í–¥í›„ 30ì¼ ì˜ˆì¸¡ ë§¤ì¶œ ë°ì´í„°:
            {predict_data_str}

            âœï¸ ì•„ë˜ í•­ëª©ì„ í¬í•¨í•´ ë¶„ì„ ë‚´ìš©ì„ 3~5ì¤„ ì •ë„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:
            1. ë§¤ì¶œì´ íŠ¹íˆ ë†’ì€ ë‚ ê³¼ ë‚®ì€ ë‚ ì€ ì–¸ì œì¸ì§€
            2. í‰ì¼ê³¼ ì£¼ë§ ë§¤ì¶œì— ì°¨ì´ê°€ ìˆëŠ”ì§€
            3. ì „ì²´ì ì¸ íë¦„ (ì¦ê°€/ê°ì†Œ ë˜ëŠ” ë³€í™” ì—†ìŒ)
            4. ì§€ë‚œ 30ì¼(ì‹¤ì œ ë§¤ì¶œ)ê³¼ í–¥í›„ 30ì¼(ì˜ˆì¸¡ ë§¤ì¶œ)ì„ ë¹„êµí•˜ì—¬ ì¢‹ì•„ì¡ŒëŠ”ì§€ ë‚˜ë¹ ì¡ŒëŠ”ì§€ ìš”ì•½
            5. ì¥ì‚¬ì— ë„ì›€ ë˜ëŠ” ì¡°ì–¸ (ì¬ê³  í™•ë³´, ì¸ë ¥ ë°°ì¹˜, ë§ˆì¼€íŒ… ì‹œì  ë“±)
            
            ğŸ“¦ ì‘ë‹µ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì´ JSON í˜•ì‹ìœ¼ë¡œ ì£¼ì„¸ìš”:

            ```json
            {{
            "summary": "ê°„ë‹¨í•œ ìš”ì•½ ë¬¸ì¥ (1~2ë¬¸ì¥)",
            "sales_pattern": "ë§¤ì¶œ íŒ¨í„´ ì„¤ëª…",
            "weekend_effect": "ì£¼ë§/í‰ì¼ ì°¨ì´ ì„¤ëª…",
            "comparison_with_last_month": "ì§€ë‚œ 30ì¼ê³¼ ë¹„êµ",
            "recommendation": "ì¥ì‚¬ì— ë„ì›€ ë˜ëŠ” ì¡°ì–¸"
            }}
            ```

            â€» ìˆ«ìë¥¼ ë„ˆë¬´ ê¸°ìˆ ì ìœ¼ë¡œ ì„¤ëª…í•˜ì§€ ë§ê³ , ê°€ê²Œ ì‚¬ì¥ë‹˜ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆê²Œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
            """

            response = self.client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=800,
                temperature=0.2,
                system=self.system_prompt,
                messages=[{"role": "user", "content": prompt}]
            )

            raw_text = response.content[0].text.strip()

            # ```json ì œê±°
            if raw_text.startswith("```json"):
                raw_text = raw_text[len("```json"):].strip()
            if raw_text.endswith("```"):
                raw_text = raw_text[:-len("```")].strip()

            # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
            result_dict = json.loads(raw_text)
            return result_dict
        
        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì˜ˆì¸¡ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return "í–¥í›„ 30ì¼ì˜ ë§¤ì¶œ íë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì¥ì‚¬ ì¤€ë¹„ì— ë„ì›€ì´ ë  ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."


    async def generate_cluster_summary(self, cluster_result: Dict[str, Any]) -> str:
        """ì†Œìƒê³µì¸ì„ ìœ„í•œ ìƒí’ˆ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì„¤ëª… ìƒì„±"""
        try:
            clusters = cluster_result.get("clusters", [])
            optimal_k = cluster_result.get("optimal_k", "ì•Œ ìˆ˜ ì—†ìŒ")
            cluster_summary = cluster_result.get("cluster_summary", {})

            prompt = f"""
            ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ë°ì´í„° ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê°€ê²Œ ìƒí’ˆì„ íŒë§¤ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ì„±ê²©ë¼ë¦¬ ë¬¶ì€ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ì…ë‹ˆë‹¤.

            ì´ {optimal_k}ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ë‰˜ì—ˆê³ , ê° ê·¸ë£¹ì— ëŒ€í•œ í†µê³„ ìš”ì•½ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

            {json.dumps(cluster_summary, ensure_ascii=False, indent=2)}

            ê° ê·¸ë£¹ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ì¥ë‹˜ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”:

            1. ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ìƒí’ˆì´ ë¬¶ì˜€ëŠ”ì§€ ì „ì²´ì ìœ¼ë¡œ ì„¤ëª…
            2. ê° ê·¸ë£¹ì˜ ëŒ€í‘œì ì¸ íŠ¹ì§•ì„ ì§§ê²Œ ì„¤ëª… (ì˜ˆ: ìì£¼ íŒ”ë¦¬ëŠ” ì €ê°€ ë©”ë‰´, ì´ìµì´ ë†’ì€ ê³ ê°€ ìƒí’ˆ ë“±)
            3. ì´ ê²°ê³¼ë¥¼ ì§„ì—´, ë§ˆì¼€íŒ…, ì„¸íŠ¸ êµ¬ì„± ë“±ì— ì–´ë–»ê²Œ í™œìš©í•˜ë©´ ì¢‹ì„ì§€ íŒ ì œì‹œ

            ğŸ“¦ ì‘ë‹µì€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ JSONìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”:

            ```json
            {{
            "summary": "í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì „ì²´ ìš”ì•½",
            "group_insight": "ìƒí’ˆë“¤ì´ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì˜€ëŠ”ì§€ ì„¤ëª…",
            "group_characteristics": [
                {{
                "group_id": 0,
                "group_name": "ê·¸ë£¹ ì´ë¦„",
                "description": "0ë²ˆ ê·¸ë£¹ì˜ ì„¤ëª…",
                "representative_items": ["í’ˆëª©1", "í’ˆëª©2", "í’ˆëª©3"]
                }},
                {{
                "group_id": 1,
                "group_name": "ê·¸ë£¹ ì´ë¦„",
                "description": "1ë²ˆ ê·¸ë£¹ì˜ ì„¤ëª…",
                "representative_items": ["í’ˆëª©4", "í’ˆëª©5", "í’ˆëª©6"]
                }}
                // ë™ì¼í•˜ê²Œ 2, 3, ... ê·¸ë£¹ì— ëŒ€í•œ ì •ë³´ ì¶”ê°€
            ],
            "recommendation": "ì‚¬ì¥ë‹˜ê»˜ ë„ì›€ì´ ë ë§Œí•œ ì œì•ˆ (ì§„ì—´, ì„¸íŠ¸ êµ¬ì„± ë“±)"
            }}
            ```
            â€» í†µê³„ ìš©ì–´ëŠ” í”¼í•˜ê³ , ì‰½ê³  ì§ê´€ì ì¸ ë§ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. 
            """

            response = self.client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1000,
                temperature=0.2,
                system=self.system_prompt,
                messages=[{"role": "user", "content": prompt}]
            )

            raw_text = response.content[0].text.strip()

            # ```json ì œê±°
            if raw_text.startswith("```json"):
                raw_text = raw_text[len("```json"):].strip()
            if raw_text.endswith("```"):
                raw_text = raw_text[:-len("```")].strip()

            # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
            result_dict = json.loads(raw_text)
            return result_dict
        
        except Exception as e:
            logger.error(f"í´ëŸ¬ìŠ¤í„°ë§ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return "ë¹„ìŠ·í•œ ìƒí’ˆë“¤ì„ ë¬¶ì–´ ì¥ì‚¬ì— ë„ì›€ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

autoanalysis_chat_service = AutoAnalysisChatService()